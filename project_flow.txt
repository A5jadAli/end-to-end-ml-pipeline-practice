Building Pipeline:
> Crrate a Github repo and clone it in your local (add a folder named experiments that will contain initial data and notebook)
> Add src folder along with all components (run them individually)
> Add data, model, reports directories to .gitignore file
> Now git add, commit, push

Setting up dvc pipeline (without params):
> Create dvc.yaml file and add stages to it
> "dvc init" then do "dvc repro" to test the pipeline automation (do "dvc dag" to see how your pipeline components are connected)
> Now git add, commit, push

Setting up dvc pipeline (with params)
> add params.yaml file
> Add the params setup (mentioned below)
> add params in dvc.yaml if not added
> do "dvc repro" again to test the pipeline with params
> Now git add, commit, push

















------------------------------------------------------------------------------------------------------------
params.yaml setup:
1> import yaml
2> add func (right after logging):
def load_params(params_path: str) -> dict:
    """Load parameters from a YAML file."""
    try:
        with open(params_path, 'r') as file:
            params = yaml.safe_load(file)
        logger.debug('Parameters retrieved from %s', params_path)
        return params
    except FileNotFoundError:
        logger.error('File not found: %s', params_path)
        raise
    except yaml.YAMLError as e:
        logger.error('YAML error: %s', e)
        raise
    except Exception as e:
        logger.error('Unexpected error: %s', e)
        raise
3> Add to main():

# data_ingestion
params = load_params(params_path='params.yaml')
test_size = params['data_ingestion']['test_size']

# feature_engineering
params = load_params(params_path='params.yaml')
max_features = params['feature_engineering']['max_features']

# model_building
params = load_params('params.yaml')['model_building']

------------------------------------------------------------------------------------------------------------